Training

Efficient Mistral training script for single GPU
Custom trainer implementation
Weight pruning: dropping every other layer
Option for LoRA
W&B logging with 10s audio prompt sampling
TODO: Weight loss on different token types
